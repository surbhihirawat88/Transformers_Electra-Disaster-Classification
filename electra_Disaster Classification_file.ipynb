{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of electra training file.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBvle-lU7BX5"
      },
      "source": [
        " \n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvrcu1JxoSjS",
        "outputId": "a681e682-7f51-4374-d696-dd20b747f03d"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():  \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    \n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzI-IavmrWrz"
      },
      "source": [
        "# Utilities\n",
        "from time import time\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import os, sys, itertools, re\n",
        "import warnings, pickle, string\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "# Translation APIs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXEyh1hrrIar",
        "outputId": "c7090aa9-9c30-4b5b-9230-62c2ee3468d2"
      },
      "source": [
        "# Block which runs on both Google Colab and Local PC without any modification\n",
        "if 'google.colab' in sys.modules:    \n",
        "    project_path = \"/content/drive/My Drive/\"\n",
        "    # Google Colab lib\n",
        "    from google.colab import drive\n",
        "    # Mount the drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    sys.path.append(project_path)\n",
        "    %cd $project_path\n",
        "\n",
        "# Let's look at the sys path\n",
        "print('Current working directory', os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive\n",
            "Current working directory /content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysJKmeEnIkPg"
      },
      "source": [
        "Overview of Dataset\n",
        "Data Format\n",
        "Each sample in the train and test set has the following information:\n",
        "\n",
        "The text of a tweet\n",
        "A keyword from that tweet (although this may be blank!)\n",
        "The location the tweet was sent from (may also be blank)\n",
        "Target\n",
        "You are predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n",
        "\n",
        "Columns\n",
        "id - a unique identifier for each tweet text - the text of the tweet location - the location the tweet was sent from (may be blank) keyword - a particular keyword from the tweet (may be blank) target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n",
        "\n",
        "NOTE: We will be using just the text and target features of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyGIKcI7ocsl"
      },
      "source": [
        "df_train=pd.read_csv('/content/drive/MyDrive/dataset/datasettt/train.csv')\n",
        "df_test=pd.read_csv('/content/drive/MyDrive/dataset/datasettt/test.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrYflO9GeSSj",
        "outputId": "bf60adff-8a9a-439d-d8a9-197fe8495bcf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_p-hKvM6omKW",
        "outputId": "8a7c1696-9845-42ff-e9d9-4ea1372e7e69"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPKcx5k5vM58"
      },
      "source": [
        "def preprocess(text):\n",
        "\n",
        "    text=text.lower()\n",
        "    # remove hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
        "    text=text.replace(r'&amp;?',r'and')\n",
        "    text=text.replace(r'&lt;',r'<')\n",
        "    text=text.replace(r'&gt;',r'>')\n",
        "    #remove hashtag sign\n",
        "    #text=re.sub(r\"#\",\"\",text)   \n",
        "    #remove mentions\n",
        "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
        "    #text=re.sub(r\"@\",\"\",text)\n",
        "    #remove non ascii chars\n",
        "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
        "    #remove some puncts (except . ! ?)\n",
        "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
        "    text=re.sub(r'[!]+','!',text)\n",
        "    text=re.sub(r'[?]+','?',text)\n",
        "    text=re.sub(r'[.]+','.',text)\n",
        "    text=re.sub(r\"'\",\"\",text)\n",
        "    text=re.sub(r\"\\(\",\"\",text)\n",
        "    text=re.sub(r\"\\)\",\"\",text)\n",
        "    \n",
        "    text=\" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess)\n",
        "df_test['text'] = df_test['text'].apply(preprocess)\n",
        "df_train=df_train[df_train[\"text\"]!='']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WJ33BufJvU5x",
        "outputId": "fecd3ab8-2caa-4080-ed9f-922acf635ef3"
      },
      "source": [
        "df_train=df_train[[\"text\",\"target\"]]\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  our deeds are the reason of this earthquake ma...       1\n",
              "1              forest fire near la ronge sask canada       1\n",
              "2  all residents asked to shelter in place are be...       1\n",
              "3  13000 people receive wildfires evacuation orde...       1\n",
              "4  just got sent this photo from ruby alaska as s...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY9xkGqrvgIx",
        "outputId": "f8863e8a-39dc-40d5-8c7f-ac0c604ebef0"
      },
      "source": [
        "df_train[\"target\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4314\n",
              "1    3247\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os9qudJqvlrf"
      },
      "source": [
        "# Get the lists of lyrics and their labels.\n",
        "texts = df_train.text.values\n",
        "labels = df_train.target.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq_tvKDDvy8v",
        "outputId": "faf1ba29-f614-4e48-d17e-a0e182ccf106"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 23.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 17.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 14.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 14.1MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 13.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 13.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=360a1f0b6076716573cc3a91877d4c17ea20d4344709b2562ceb48c2ab892707\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5qWT8Szvqo7",
        "outputId": "e7f1d43b-0c11-4cc0-acb3-09bb20814c27"
      },
      "source": [
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n",
        "import torch\n",
        "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
        "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "5lrbDcE3vxiK",
        "outputId": "b254b1c2-6224-4651-d057-6d277d8e5adc"
      },
      "source": [
        "#to show length of embedding will be helpful to determine maximum length of comments and padding threshold\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
        "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
        "    fig, ax = plt.subplots(figsize=(8, 5));\n",
        "    ax.hist(tokenized_texts_len, bins=40);\n",
        "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
        "    ax.set_ylabel(\"Number of Comments\");\n",
        "    return\n",
        "plot_sentence_embeddings_length(texts, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdEePUJ8wFiC",
        "outputId": "2f4285aa-671c-402b-911b-5bbf0dde0369"
      },
      "source": [
        "\n",
        "\n",
        "indices=tokenizer.batch_encode_plus(texts,max_length=64,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
        "\n",
        "input_ids=indices[\"input_ids\"]\n",
        "attention_masks=indices[\"attention_mask\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUhpE85YwM7P"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 99% for training and 1% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=42, test_size=0.2)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=42, test_size=.2)\n",
        "                                            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA4R_AJOwRHf"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
        "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
        "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iL_WNWIyVnC"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Nu_dPyyZkX"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 6e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 10\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iomwNTBhyqOl"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlbxzLM2yu7X"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwXLFQeAy1_q",
        "outputId": "18e08d3b-0e7c-4762-a5b9-009a687859e2"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 100 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "      \n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:21.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:41.\n",
            "  Batch   150  of    189.    Elapsed: 0:01:00.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:40.\n",
            "  Batch   150  of    189.    Elapsed: 0:01:00.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epoch took: 0:01:14\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epoch took: 0:01:14\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epoch took: 0:01:14\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:40.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    50  of    189.    Elapsed: 0:00:20.\n",
            "  Batch   100  of    189.    Elapsed: 0:00:39.\n",
            "  Batch   150  of    189.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epoch took: 0:01:14\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72oiDjEy8Hh",
        "outputId": "dc4524e8-1638-4440-ac1a-c71f87d2aa1c"
      },
      "source": [
        "#               Validation\n",
        "# ========================================\n",
        "# After the completion of each training epoch, measure our performance on\n",
        "# our validation set.\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "preds=[]\n",
        "true=[]\n",
        "\n",
        "# Tracking variables \n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    preds.append(logits)\n",
        "    true.append(label_ids)\n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    # Accumulate the total accuracy.\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    # Track the number of batches\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9eD1HJN691I"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in preds for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie3iRaeZ7G5v",
        "outputId": "a109489a-e945-44b1-ec74-3b0963c57363"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(flat_predictions,flat_true_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83       883\n",
            "           1       0.76      0.78      0.77       630\n",
            "\n",
            "    accuracy                           0.81      1513\n",
            "   macro avg       0.80      0.80      0.80      1513\n",
            "weighted avg       0.81      0.81      0.81      1513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDTwsYFzjM44"
      },
      "source": [
        "PATH = \"/content/drive/MyDrive/dataset/datasettt/state_electra_model.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(model,PATH) \n",
        "\n",
        "# # Load\n",
        "\n",
        "# model.load_state_dict(torch.load(PATH))\n",
        "# model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0iybxsSslgr",
        "outputId": "07dd9214-ad04-49d9-932c-7a3e7f6177a6"
      },
      "source": [
        "# Load\n",
        "# Load\n",
        "model = torch.load(PATH,map_location='cpu')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqXmGhySqnRK"
      },
      "source": [
        "\n",
        "def predict(model, tokenizer, text):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    tokenized = tokenizer.encode(text, add_special_tokens=True)\n",
        "    tok_tensor = torch.tensor(tokenized).to(device)\n",
        "    tok_tensor = tok_tensor.unsqueeze(0)\n",
        "    logits = model(tok_tensor)\n",
        "    pred = torch.sigmoid(logits)\n",
        "    pred = pred.detach().cpu().numpy()\n",
        "    \n",
        "    result_df = pd.DataFrame(pred, columns=labels_list)\n",
        "    results = result_df.to_dict(\"record\")\n",
        "\n",
        "    return [sorted(x.items(), key=lambda kv: kv[1], reverse=True) for x in results][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm9sz9nd7KL3",
        "outputId": "464fa151-76c7-4b75-e4e8-80ca207b4669"
      },
      "source": [
        "comments1 = df_test.text.values\n",
        "\n",
        "indices1=tokenizer.batch_encode_plus(comments1,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
        "input_ids1=indices1[\"input_ids\"]\n",
        "attention_masks1=indices1[\"attention_mask\"]\n",
        "\n",
        "prediction_inputs1= torch.tensor(input_ids1)\n",
        "prediction_masks1 = torch.tensor(attention_masks1)\n",
        "\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32 \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
        "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
        "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbAEQ8yjBZqY",
        "outputId": "33a3b4b7-1e29-4a82-ebf4-e5220f6142f0"
      },
      "source": [
        "\n",
        "# The name of the folder containing the model files.\n",
        "\n",
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n",
        "import torch\n",
        "tokenizer1 = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
        "model1 = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
        "model1.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model1.cuda\n",
        "model1.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCugkpww7RlZ",
        "outputId": "f9a2bb1b-d881-4a66-f5ea-465c9d6c8aff"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model1.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader1:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs1 = model1(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits1 = outputs1[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits1 = logits1.detach().cpu().numpy()\n",
        "  \n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits1)\n",
        "\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,263 test sentences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBn_UKda3whO",
        "outputId": "5fe8e344-a525-430c-d284-cd5022d52c78"
      },
      "source": [
        "flat_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tGMfb9W7eQu"
      },
      "source": [
        "sample_sub=pd.read_csv('/content/drive/MyDrive/dataset/datasettt/test.csv')\n",
        "submit=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':flat_predictions})\n",
        "submit.to_csv('qwsubmission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fTxOD-lr7oNZ",
        "outputId": "b4a17a5f-9613-4342-ecae-91914fa06037"
      },
      "source": [
        "submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       1\n",
              "1   2       1\n",
              "2   3       1\n",
              "3   9       1\n",
              "4  11       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hskaVte7OXmR"
      },
      "source": [
        "df_test['target'] = submit['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Eysr1INYShfC",
        "outputId": "1dca2134-6b0d-4b05-ae71-abd39f9e5c07"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>just happened a terrible car crash</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>heard about earthquake is different cities sta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond geese are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apocalypse lighting spokane wildfires</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>typhoon soudelor kills 28 in china and taiwan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>earthquake safety los angeles safety fasteners...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>storm in ri worse than last hurricane my citya...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>green line derailment in chicago</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>meg issues hazardous weather outlook hwo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cityofcalgary has activated its municipal emer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword  ...                                               text target\n",
              "0         0     NaN  ...                 just happened a terrible car crash      1\n",
              "1         2     NaN  ...  heard about earthquake is different cities sta...      1\n",
              "2         3     NaN  ...  there is a forest fire at spot pond geese are ...      1\n",
              "3         9     NaN  ...              apocalypse lighting spokane wildfires      1\n",
              "4        11     NaN  ...      typhoon soudelor kills 28 in china and taiwan      1\n",
              "...     ...     ...  ...                                                ...    ...\n",
              "3258  10861     NaN  ...  earthquake safety los angeles safety fasteners...      0\n",
              "3259  10865     NaN  ...  storm in ri worse than last hurricane my citya...      1\n",
              "3260  10868     NaN  ...                   green line derailment in chicago      1\n",
              "3261  10874     NaN  ...           meg issues hazardous weather outlook hwo      1\n",
              "3262  10875     NaN  ...  cityofcalgary has activated its municipal emer...      1\n",
              "\n",
              "[3263 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGQO2fDgSpti",
        "outputId": "ca79b8be-fbce-43d9-cb07-c5dd47c851e5"
      },
      "source": [
        "text = [\"Virat Kohli, AB de Villiers set to auction their 'Green Day' kits from 2016 IPL match to raise funds\"]\n",
        "\n",
        "indices1=tokenizer.batch_encode_plus(text,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
        "input_ids1=indices1[\"input_ids\"]\n",
        "attention_masks1=indices1[\"attention_mask\"]\n",
        "\n",
        "prediction_inputs1= torch.tensor(input_ids1)\n",
        "prediction_masks1 = torch.tensor(attention_masks1)\n",
        "\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32 \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
        "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
        "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In2mYgWmdONv"
      },
      "source": [
        "def Prediction(text):\n",
        "  # Put model in evaluation mode\n",
        "  model1.eval()\n",
        "# Tracking variables \n",
        "  predictions = []\n",
        "# Predict \n",
        "  for batch in prediction_dataloader1:\n",
        "  # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs1 = model1(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "    logits1 = outputs1[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "    logits1 = logits1.detach().cpu().numpy()\n",
        "  # Store predictions and true labels\n",
        "    predictions.append(logits1)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    return flat_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCL_nwZLdTcl",
        "outputId": "9cda1935-0ee4-4e4e-b3e6-2e55667ed48f"
      },
      "source": [
        "Prediction(prediction_dataloader1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXElvRRbfeFH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}